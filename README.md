### Исследовательская работа анализ времени выполнения алгоритмов сортировки и диапазона целых значений массивов 
## Гипотеза
Counting sort и Radix sort - эффективнее других сортировок при ограниченном диапазоне значений.

## Используемые алгоритмы


## Амортизационный анализ сложности сортировки слиянием (Merge Sort)

Сортировка слиянием (Merge Sort) — это классический алгоритм сортировки, применяющий подход "разделяй и властвуй". Основная идея алгоритма заключается в разделении массива на меньшие части, сортировке этих частей и последующем их слиянии. Merge Sort отличается стабильной высокой производительностью и является одним из самых эффективных методов сортировки на практике.

### Сложность алгоритма

#### Временная сложность

- **Худший случай**: \(O(n \log n)\)
- **Лучший случай**: \(O(n \log n)\)
- **Средний случай**: \(O(n \log n)\)

Независимо от начального порядка элементов, Merge Sort всегда разделяет массив на две равные части (или приблизительно равные), затем рекурсивно сортирует эти части и сливает их вместе. Разделение массива происходит логарифмическое количество раз (поскольку каждое разделение уменьшает размер задачи вдвое), а процесс слияния каждый раз требует линейного времени относительно размера массива. Это приводит к временной сложности \(O(n \log n)\).

Сортировка слиянием не зависит от диапазона входных значений, поскольку она не основывается на сравнении ключей напрямую для определения позиции элемента, а скорее сосредоточена на слиянии предварительно отсортированных списков. Это делает её особенно устойчивой к вариациям во входных данных и эффективной для сортировки данных с большими или малыми диапазонами значений без какого-либо ухудшения производительности.


### Амортизационный анализ

Амортизационный анализ не является стандартным при рассмотрении сортировки слиянием, так как алгоритм не включает операции, которые имеют разную стоимость в зависимости от текущего состояния структуры данных. Временная сложность Merge Sort стабильна и не изменяется в зависимости от предыдущих операций или распределения данных.

### Анализ требуемой дополнительной памяти

Merge Sort требует дополнительной памяти для хранения временных массивов при слиянии отсортированных частей.

#### Требуемая память: \(O(n)\)

1. **Рекурсивное разделение**: При рекурсивном разделении массива не создаются новые массивы, происходит только передача указателей на начальные и конечные точки подмассивов исходного массива.

2. **Слияние**: Для процесса слияния необходимо создать временный массив, в котором будут храниться отсортированные элементы перед их копированием обратно в исходный массив. Размер этого массива в наихудшем случае равен размеру исходного массива \(n\), что обеспечивает хранение всех элементов при слиянии.

### Заключение

Merge Sort демонстрирует высокую эффективность и стабильность по времени выполнения за счет логарифмического количества уровней рекурсии и линейного времени на каждом уровне для слияния. Основной недостаток — требование дополнительной памяти размером \(O(n)\), что делает его менее предпочтительным для ограниченных по памяти систем по сравнению с алгоритмами сортировки, которые работают "на месте", такими как Quick Sort.

## Анализ сложности быстрой сортировки (Quick Sort)

Быстрая сортировка, известная также как Quick Sort, является одним из наиболее широко используемых алгоритмов сортировки, основанных на подходе "разделяй и властвуй". Она была разработана Тони Хоаром в 1960 году и до сих пор используется во множестве приложений благодаря своей эффективности на практике.

### Сложность алгоритма

#### Временная сложность

- **Худший случай**: \(O(n^2)\)
- **Лучший случай**: \(O(n \log n)\)
- **Средний случай**: \(O(n \log n)\)

#### Пояснение

Временная сложность быстрой сортировки зависит от выбора опорного элемента:
- В **лучшем случае**, когда опорный элемент делит массив на две равные части, быстрая сортировка достигает временной сложности \(O(n \log n)\).
- В **худшем случае**, когда опорный элемент оказывается наименьшим или наибольшим элементом в массиве, сложность алгоритма возрастает до \(O(n^2)\).
- **Средний случай** также имеет сложность \(O(n \log n)\), предполагая случайный выбор опорного элемента или использование стратегий, таких как "медиана из трех".

### Амортизационный анализ

Амортизационный анализ для быстрой сортировки обычно не применяется, поскольку алгоритм не выполняет операции с переменной стоимостью в зависимости от состояния структуры данных в отличие от структур с амортизированными гарантиями времени выполнения.

### Анализ требуемой дополнительной памяти

Быстрая сортировка является алгоритмом "на месте" и потенциально может требовать лишь небольшого дополнительного пространства для стека вызовов при использовании рекурсии:

#### Требуемая память: \(O(\log n)\) (в среднем случае)

- **Рекурсивное разделение**: Не требует дополнительной памяти для хранения данных, однако использует стек вызовов, который в среднем будет иметь глубину \(\log n\), что соответствует количеству уровней рекурсии.
- **Худший случай**: Глубина рекурсивного стека может достичь \(n\) в случае очень неудачного выбора опорных элементов на каждом шаге рекурсии.
Эффективность быстрой сортировки может зависеть от диапазона входных значений в том случае, если выбор опорного элемента приводит к слишком несбалансированным разделениям. Особенно это заметно, если все или большинство входных данных сосредоточены вокруг одного значения или если они распределены неравномерно вокруг выбранного опорного элемента. В таких случаях, оптимальный выбор опорного элемента — ключ к поддержанию производительности \(O(n \log n)\). В противном случае, если опорный элемент систематически оказывается крайним (наименьшим или наибольшим значением), сложность алгоритма может деградировать до \(O(n^2)\), что существенно снижает его производительность.

### Заключение

Быстрая сортировка чрезвычайно эффективна и широко используется благодаря своей способности быстро обрабатывать большие массивы данных. Её эффективность особенно заметна, когда опорный элемент выбирается так, чтобы он делил массив на примерно равные части. Недостаток в потенциальной сложности \(O(n^2)\) может быть минимизирован за счет интеллектуального выбора опорного элемента или смешивания с другими алгоритмами сортировки при малых размерах подмассивов.


## Анализ сложности сортировки кучей (Heap Sort)

Сортировка кучей (Heap Sort) — это популярный алгоритм сортировки, использующий бинарную кучу для организации элементов массива. Этот метод сортировки применяет двоичное дерево и подход "разделяй и властвуй", гарантируя стабильную производительность даже на больших объемах данных.


#### Временная сложность

- **Худший случай**: \(O(n \log n)\)
- **Лучший случай**: \(O(n \log n)\)
- **Средний случай**: \(O(n \log n)\)

#### Пояснение

Сортировка кучей всегда гарантирует временную сложность \(O(n \log n)\) благодаря свойствам бинарной кучи, где каждая операция вставки и удаления выполняется за время, пропорциональное высоте дерева (которая равна \(\log n\)). Процесс состоит из построения максимальной кучи из массива и последовательного удаления наибольшего элемента кучи, который заменяется последним элементом кучи и "просеивается" вниз для восстановления свойств кучи.

### Анализ требуемой дополнительной памяти

- **Требуемая память**: \(O(1)\)

Сортировка кучей выполняется "на месте" в исходном массиве. Весь процесс управления кучей происходит в пределах самого массива, за исключением небольшого фиксированного количества дополнительных переменных для отслеживания индексов и промежуточных значений. Это делает Heap Sort особенно эффективным с точки зрения использования памяти.

### Зависимость от диапазона значений

Эффективность сортировки кучей не зависит от диапазона входных значений, поскольку алгоритм основан на свойствах кучи, а не на сравнении разнообразия или распределении ключей. Вне зависимости от того, насколько велик или мал диапазон значений, время выполнения сортировки определяется исключительно количеством элементов и их организацией в куче.

### Заключение

Heap Sort предоставляет надежную производительность \(O(n \log n)\) и минимальное потребление дополнительной памяти, что делает его идеальным выбором для задач, где важны как скорость, так и эффективность использования ресурсов. Отсутствие зависимости от распределения входных данных делает его универсальным инструментом для широкого спектра приложений.

## Анализ сложности сортировки подсчетом (Counting Sort)

Сортировка подсчетом (Counting Sort) — это алгоритм сортировки, который считается особенно эффективным при сортировке целых чисел или других объектов, когда ключи элементов находятся в небольшом диапазоне. Этот метод не основан на сравнении элементов, а скорее использует индексированный массив для подсчета встречаемости каждого возможного значения входного массива.

### Сложность алгоритма

#### Временная сложность

- **Худший случай**: \(O(n + k)\)
- **Лучший случай**: \(O(n + k)\)
- **Средний случай**: \(O(n + k)\)

где `n` — количество элементов в исходном массиве, а `k` — размер диапазона входных данных.

#### Пояснение

Сложность сортировки подсчетом фиксирована и зависит от количества обрабатываемых элементов и размаха значений (диапазона). Алгоритм проходит через входные данные для подсчета каждого значения, затем вычисляет начальные позиции для каждого ключа в отсортированном массиве, и, наконец, строит отсортированный массив.

### Анализ требуемой дополнительной памяти

- **Требуемая память**: \(O(n + k)\)

Алгоритм требует дополнительного пространства не только для хранения счётчиков каждого уникального элемента (что составляет `k`), но и для временного массива, который хранит отсортированный результат (размер `n`).

### Зависимость от диапазона значений

Эффективность сортировки подсчетом сильно зависит от значения `k` — размаха входных данных. Если `k` существенно меньше `n`, то сортировка будет крайне эффективной. Однако, если `k` приближается к `n` или превышает его, преимущества сортировки подсчетом могут уменьшаться, так как требуемое дополнительное пространство и время на инициализацию счётчиков увеличиваются.

### Заключение

Counting Sort идеально подходит для сортировки больших объемов данных, когда известно, что диапазон значений не слишком велик. Это обеспечивает быструю и стабильную производительность и делает Counting Sort предпочтительным выбором в специфических случаях использования, таких как сортировка символов или целых чисел с ограниченным набором возможных значений.

## Анализ сложности поразрядной сортировки (Radix Sort)

Поразрядная сортировка (Radix Sort) — это алгоритм сортировки, который обрабатывает информацию по разрядам, начиная с наименее значимого разряда и заканчивая наиболее значимым. Этот метод особенно эффективен при сортировке больших массивов чисел, когда ключи распределены в пределах ограниченного диапазона.

### Сложность алгоритма

#### Временная сложность

- **Худший случай**: \(O(nk)\)
- **Лучший случай**: \(O(nk)\)
- **Средний случай**: \(O(nk)\)

где `n` — количество элементов в массиве, а `k` — количество разрядов в максимальном ключе.

#### Пояснение

Временная сложность поразрядной сортировки зависит от количества разрядов (цифр) в наибольшем числе (`k`) и количества элементов в массиве (`n`). Для каждого разряда алгоритм применяет стабильную сортировку подсчетом, которая занимает \(O(n)\) времени. Так как этот процесс повторяется для каждого из `k` разрядов, общая временная сложность составляет \(O(nk)\).

### Анализ требуемой дополнительной памяти

#### Требуемая память: \(O(n + k)\)

- **Пояснение**: Radix Sort требует дополнительного пространства для хранения:
  - Временного массива (`output`) для размещения элементов после сортировки каждого разряда, размер которого равен `n`.
  - Массива (`count`) для подсчета вхождений каждой возможной цифры (от 0 до 9), размер которого равен `10` (постоянная `k`, которая в данном случае не зависит от `k` в определении сложности).

### Зависимость от диапазона значений

Эффективность поразрядной сортировки сильно зависит от значения `k` — числа разрядов в наибольшем числе массива. Если `k` существенно меньше, чем `n`, то сортировка будет очень эффективной. Однако, если `k` приближается к `n` или превышает его, то преимущества поразрядной сортировки уменьшаются из-за увеличения затрат времени и памяти.

### Заключение

Radix Sort обеспечивает эффективную обработку больших массивов, когда ключи распределены в узком диапазоне. Он особенно полезен, когда `k` невелико по сравнению с `n`, обеспечивая при этом линейное время выполнения. Однако потребность в дополнительной памяти делает его менее подходящим для сценариев с ограниченными ресурсами памяти.


## Анализ сложности пузырьковой сортировки (Bubble Sort)

Пузырьковая сортировка (Bubble Sort) является одним из самых простых алгоритмов сортировки. Она работает путём многократного прохода по списку, сравнения соседних элементов и их обмена, если они находятся в неправильном порядке. Этот процесс повторяется до тех пор, пока список не будет отсортирован.

### Сложность алгоритма

#### Временная сложность

- **Худший случай**: \(O(n^2)\)
- **Лучший случай**: \(O(n)\) (когда массив уже отсортирован)
- **Средний случай**: \(O(n^2)\)

#### Пояснение

Сложность пузырьковой сортировки в худшем и среднем случаях составляет \(O(n^2)\), что делает её неэффективной для больших массивов. Это связано с тем, что каждый элемент сравнивается с каждым другим, что требует \(n(n-1)/2\) сравнений и обменов в худшем случае. В лучшем случае, когда массив уже отсортирован, она проходит по массиву один раз и выполняет \(n-1\) сравнений без каких-либо перестановок.

### Анализ требуемой дополнительной памяти

- **Требуемая память**: \(O(1)\)

Пузырьковая сортировка является сортировкой "на месте", что означает, что она не требует дополнительного пространства для других массивов. Весь процесс сортировки происходит в исходном массиве, что делает её пространственно эффективной.

### Зависимость от диапазона значений

Эффективность пузырьковой сортировки не зависит напрямую от диапазона значений, но чрезвычайно зависит от начального порядка элементов в массиве. Если элементы уже близки к итоговой сортировке или полностью отсортированы, пузырьковая сортировка будет выполняться значительно быстрее. Однако, даже при небольших массивах с полностью случайным порядком элементов, её производительность быстро ухудшается.

### Заключение

Пузырьковая сортировка полезна в образовательных целях и для сортировки небольших массивов, где простота реализации является более важной, чем оптимальность производительности. На практике существует множество более эффективных алгоритмов, таких как быстрая сортировка, сортировка слиянием или даже сортировка вставками, которые лучше подходят для обработки больших объемов данных.


## Глобальный вывод о работе алгоритмов сортировки

Представленный график времени выполнения различных алгоритмов сортировки в зависимости от размера массива позволяет сравнить их производительность, особенно учитывая увеличенный диапазон входных значений.

### Наблюдения:
- **Bubble Sort** продолжает показывать значительно худшую производительность, особенно на больших массивах, что подтверждает её \(O(n^2)\) временную сложность.
- **Radix Sort** и **Counting Sort** проявляют отличную производительность на малых и средних массивах, но время их выполнения начинает расти на больших массивах с расширенным диапазоном значений.
- **Merge Sort**, **Quick Sort** и **Heap Sort** продемонстрировали схожие и сравнительно низкие времена выполнения на всех тестовых массивах, подтверждая их \(O(n \log n)\) производительность.

### Рекомендации:
- Если диапазон входных данных мал, **Radix Sort** или **Counting Sort** могут предложить лучшую производительность за счет \(O(n + k)\) сложности.
- Для более универсальных сценариев и больших размеров массивов **Quick Sort**, **Merge Sort**, и **Heap Sort** являются более предпочтительными за счет их \(O(n \log n)\) временной сложности и независимости от диапазона значений.

### Визуализация результатов:

![Sorting Algorithm Performance Graph](diapoz.png)

*График демонстрирует время выполнения различных алгоритмов сортировки в зависимости от размера массива, с учётом увеличенного диапазона значений.*

### Заключение:
Пузырьковая сортировка не рекомендуется для практического использования, особенно на больших данных. Сортировки подсчетом и поразрядная могут быть эффективны при небольшом диапазоне значений. В случаях, когда диапазон значений велик, **Merge Sort**, **Quick Sort**, и **Heap Sort** предложат лучшую производительность и стабильность.
### Вывод 
- Итого мы смогли доказать, что Counting sort, эффективнее использовать на больших массивов данных даже с учетом диапазона чисел отвечаюшими диапазону чисел положительного int. Но лучшую эффективность показала программма, когда диапазон чисел уменьшался.
- Radix sort при небольших диапазаонах значений показывает также большую эффектиность чем стандартные сортировки, но уступает Counting sort, а также при большом разбросе данных уступает стандартным сортировкам 


